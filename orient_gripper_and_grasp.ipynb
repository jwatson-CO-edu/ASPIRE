{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpie import grasp as gt\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "from magpie.motor_code import Motors\n",
    "from magpie import ur5 as ur5\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import magpie\n",
    "from magpie.gripper import Gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from magpie.perception import pcd\n",
    "from open3d.web_visualizer import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpie import realsense_wrapper as real\n",
    "rsc = real.RealSense()\n",
    "rsc.initConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 15:58:59.955158: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 15:59:00.702619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from magpie.perception.label_owlvit import LabelOWLViT\n",
    "path = \"google/owlvit-base-patch32\"\n",
    "label_vit = LabelOWLViT(pth=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'magpie.gripper' from '/home/will/MAGPIE/magpie/gripper.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gt)\n",
    "importlib.reload(ur5)\n",
    "importlib.reload(magpie.gripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg(index):\n",
    "    p, rgbd_image = rsc.getPCD()\n",
    "    image = np.array(rgbd_image.color)\n",
    "    queries = [\"a photo of an apple\", \"a photo of a lemon\", \"a photo of a lime\", \"a photo of a pear\", \"a photo of a onion\"]\n",
    "    queries = [\"a photo of an blue cylindrical container\", \"a photo of a small red cubic block\", \"a photo of a screwdriver handle\" ]\n",
    "    queries = [\"a photo of a black student ID card\", \"a photo of a small orange fruit\", \"a photo of a small plastic bag\"]\n",
    "    queries = [\"a photo of an avocado\", \"a photo of a small orange fruit\", \"a photo of a small plastic bag\", \"a photo of a paper airplane\"]\n",
    "    queries = [\"a photo of a water bottle with a red top\"]\n",
    "    queries = [\"a photo of a blue block\"]\n",
    "    # queries = [\"a photo of a tail\"]\n",
    "    # queries = [\"a photo of a black handle of a pair of scissors\"]\n",
    "    abbrevq = [\"apple\", \"lemon\", \"lime\", \"pear\", \"onion\"]\n",
    "    abbrevq = [\"blue\", \"block\", \"handle\"]\n",
    "    abbrevq = [\"card\", \"orange\", \"bag\"]\n",
    "    abbrevq = [\"avocado\", \"orange\", \"bag\", \"paper airplane\"]\n",
    "    abbrevq = [\"block\"]\n",
    "    label_vit.set_threshold(0.005)\n",
    "    # bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=True)\n",
    "    bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=False)\n",
    "    rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "                                            label_vit.sorted_labeled_boxes_coords, \n",
    "                                            # label_vit.boxes, \n",
    "                                            index, \n",
    "                                            rgbd_image, \n",
    "                                            rsc, \n",
    "                                            type=\"box-dbscan\", \n",
    "                                            #  type=\"box\", \n",
    "                                            #  method=\"quat\", \n",
    "                                            method=\"iterative\", \n",
    "                                            #  display=False,\n",
    "                                            display=False,\n",
    "                                            viz_scale=1000)\n",
    "    tmat, tmat[:3, 3]\n",
    "    \n",
    "    return cpcd, tmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrays in saved_poses/ folder as array of arrays\n",
    "saved_poses = []\n",
    "for i in range(5):\n",
    "    saved_poses.append(np.load(f'saved_poses/pose_{i+1}.npy', allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n",
      "Moving speed of dxl ID: 1 set to 100 \n",
      "Moving speed of dxl ID: 2 set to 100 \n",
      "  \u001b[38;5;1m-0.2421  \u001b[0m \u001b[38;5;1m-0.9517  \u001b[0m \u001b[38;5;1m 0.189   \u001b[0m \u001b[38;5;4m-0.4225  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.8953  \u001b[0m \u001b[38;5;1m 0.2942  \u001b[0m \u001b[38;5;1m 0.3344  \u001b[0m \u001b[38;5;4m 0.01022 \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.3738  \u001b[0m \u001b[38;5;1m-0.08828 \u001b[0m \u001b[38;5;1m-0.9233  \u001b[0m \u001b[38;5;4m 0.165   \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 1       \u001b[0m  \u001b[0m\n",
      "\n",
      "modified indices: [0 1 2]\n",
      "z-axis dot product: [-0.297]\n",
      "flipping z axis\n",
      "flipping x-axis\n",
      "modified indices: [2 1 1]\n",
      "modified indices: [2 0 1]\n",
      "z-axis dot product: [0.975]\n",
      "modified indices: [2 2 1]\n",
      "modified indices: [2 0 1]\n",
      "z-axis dot product: [0.902]\n",
      "modified indices: [0 2 2]\n",
      "modified indices: [0 1 2]\n",
      "z-axis dot product: [0.988]\n",
      "modified indices: [0 0 2]\n",
      "modified indices: [0 1 2]\n",
      "z-axis dot product: [0.926]\n"
     ]
    }
   ],
   "source": [
    "# move gripper to cartesian pos\n",
    "# OR orient gripper in place\n",
    "name = \"pose_5\"\n",
    "sleepRate = 3\n",
    "# time.sleep(sleepRate)\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    print(currentPose)\n",
    "    # save pose to npy\n",
    "    for k, i in enumerate(saved_poses):\n",
    "        if k == 4:\n",
    "            ind = 1\n",
    "        else: \n",
    "            ind = 0\n",
    "        # print(f\"moving to pose {i + 1}: {saved_poses[i]}\")\n",
    "        ur.moveL(i)\n",
    "        time.sleep(sleepRate)\n",
    "        time.sleep(sleepRate)\n",
    "        cpcd, tmat = seg(ind)\n",
    "        o3d.io.write_point_cloud(f\"saved_pcd/cpcd{k+1}.ply\", cpcd)\n",
    "        tt = ur.get_tcp_pose()\n",
    "        tmat1 = np.array([[ 1, 0,  0, 0],\n",
    "       [0, 1,  0,  0],\n",
    "       [ 0,  0,  1,  0.08],\n",
    "       [ 0,  0,  0,  1]])\n",
    "        #tmat = np.matmul(tmat, tmat1)\n",
    "        cpcd.transform(tmat)\n",
    "        cpcd.transform(tmat1)\n",
    "        cpcd.transform(tt)\n",
    "        o3d.io.write_point_cloud(f\"saved_pcd/cpcd{k+1}_t.ply\", cpcd)\n",
    "\n",
    "\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = o3d.io.read_point_cloud(f\"saved_pcd/cpcd1_t.ply\")\n",
    "for i in range(1,4):\n",
    "    cpcd = o3d.io.read_point_cloud(f\"saved_pcd/cpcd{i+1}_t.ply\")\n",
    "    merged += cpcd\n",
    "o3d.visualization.draw_geometries([merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matrix\n",
    "# tmat = np.array([[ 0.91574736, -0.35602909,  0.18614527, -0.02848649],\n",
    "#        [-0.40073104, -0.77640133,  0.48643151,  0.14332736],\n",
    "#        [ 0.02866033,  0.52004256,  0.85365937,  0.33750796],\n",
    "#        [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "tmat = np.array([[ 0.98665647, -0.16180182, -0.01814324,  0.04438557],\n",
    "       [-0.1565328 , -0.97333117,  0.16770185,  0.04194964],\n",
    "       [ 0.04479385,  0.1626241 ,  0.98567079,  0.32025074],\n",
    "       [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "aperture = 37\n",
    "# z_offset = G.aperture_to_z(aperture)/1000.0\n",
    "\n",
    "mmc = copy.deepcopy(tmat[:3, 3])\n",
    "# grasp_pose = [mmc[1], -mmc[0], mmc[2]]\n",
    "grasp_pose = mmc\n",
    "tmat[:3, 3] = [0, 0, 0]\n",
    "homePose = None\n",
    "z_offset = 100/1000.0\n",
    "z_offset -= 0.035\n",
    "z_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move gripper to cartesian pos\n",
    "# OR orient gripper in place\n",
    "name = \"pose_5\"\n",
    "sleepRate = 4\n",
    "# time.sleep(sleepRate)\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    print(currentPose)\n",
    "\n",
    "    ur.moveL(saved_poses[4])\n",
    "    time.sleep(sleepRate)\n",
    "    time.sleep(sleepRate)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "# this does the [x, y, z] --> [y, -x, z] grasp pose switch, and the -y inversio on the y-axis orientation\n",
    "# rgbd_image, cpcd, tmat = pcd|.get_segment(label_vit.boxes, index, rgbd_image, rsc, type=\"box\", display=False)\n",
    "rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "                                        label_vit.sorted_labeled_boxes_coords, \n",
    "                                        # label_vit.boxes, \n",
    "                                         index, \n",
    "                                         rgbd_image, \n",
    "                                         rsc, \n",
    "                                         type=\"box-dbscan\", \n",
    "                                        #  type=\"box\", \n",
    "                                        #  method=\"quat\", \n",
    "                                         method=\"iterative\", \n",
    "                                        #  display=False,\n",
    "                                         display=True,\n",
    "                                         viz_scale=1000)\n",
    "tmat, tmat[:3, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move gripper to cartesian pos\n",
    "# OR orient gripper in place\n",
    "sleepRate = 1.5\n",
    "# time.sleep(sleepRate)\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    # homePose = ur.get_tcp_pose()\n",
    "    homePose = ur.getPose()\n",
    "    currentPose = ur.getPose()\n",
    "    desiredPose = np.matmul(np.array(currentPose), tmat)\n",
    "    print(\"Desired Pose: \", desiredPose)\n",
    "    # in-place (or best attempt) re-orientation\n",
    "    # ur.moveL(desiredPose)\n",
    "    ## move to cartesian pos\n",
    "    gt.move_to_L(grasp_pose, ur, z_offset=z_offset)    \n",
    "    print(\"Done moving to block\")\n",
    "    time.sleep(sleepRate)\n",
    "    time.sleep(sleepRate)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move home\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    # time.sleep(sleepRate)\n",
    "    # homePose = np.array([[-0.024, -0.998, -0.062, -0.261],\n",
    "    #                     [-0.999,  0.021,  0.035, -0.162],\n",
    "    #                     [-0.033,  0.063, -0.997,  0.221],\n",
    "    #                     [ 0.   ,  0.   ,  0.   ,  1.   ]])\n",
    "    ur.moveL(homePose)\n",
    "    # gt_home = ur.getPose()\n",
    "    # print(np.array(gt_home))\n",
    "    time.sleep(sleepRate * 3)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # orient and move gripper to cartesian pos\n",
    "# sleepRate = 1.5\n",
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     servoPort = \"/dev/ttyACM0\"\n",
    "#     ur.start()\n",
    "#     time.sleep(sleepRate)\n",
    "#     homePose = ur.get_tcp_pose()    \n",
    "#     '''\n",
    "#     stopping point 2/15:\n",
    "#     this works so far\n",
    "#     take home pos\n",
    "#     add translation on the gripper frame to the goal x, y\n",
    "#     apply tmat to the goal\n",
    "#     move to goal (translates on x, y and orients at the same time)\n",
    "#     ## does this address the fact that orientation is not achievable in standstill?\n",
    "\n",
    "#     then: take orig Z (from original gripper frame): [0, 0, dZ]\n",
    "#     transform by tmat (the current orientation of the gripper)\n",
    "#     add transformed dZ to the goal position\n",
    "#     move\n",
    "#     works!\n",
    "#     '''\n",
    "#     dX,dY,dZ = gt.get_world_frame(grasp_pose, ur, z_offset=z_offset)\n",
    "\n",
    "#     goal1 = copy.deepcopy(homePose)\n",
    "#     goal1 = np.array(goal1)\n",
    "#     # goal1[:3, 3] += [dX, dY, 0]\n",
    "#     goal1[:3, 3] += [dX, dY, dZ]\n",
    "#     goal1 = np.array(goal1) @ tmat\n",
    "#     ur.moveL(goal1)\n",
    "#     time.sleep(sleepRate)\n",
    "\n",
    "#     # todo: take currentPose and validate orientation?\n",
    "#     goal2 = goal1\n",
    "#     posd = [0, 0, dZ] @ tmat[:3, :3]\n",
    "#     goal2 = np.array(goal2)\n",
    "#     goal2[:3, 3] += posd\n",
    "#     # ur.moveL(goal2)\n",
    "#     time.sleep(sleepRate)\n",
    "#     '''\n",
    "#     end of working section\n",
    "#     '''\n",
    "#     ur.stop()\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
